
import pandas as pd
df = pd.read_csv('part1_station_data.csv')
yelp_df = pd.read_csv('part2_yelp_data.csv')
foursquare_df = pd.read_csv('part2_foursquare_data.csv')

merged_df = pd.merge(df, foursquare_df, on=['latitude', 'longitude'], how='left')
merged_df = pd.merge(merged_df, yelp_df, on=['latitude', 'longitude'], how='left', suffixes=('_foursquare', '_yelp'))

merged_df

# Check for missing values and calculate the count of missing values in each column
missing_values = merged_df.isnull().sum()

# Print the columns with missing values and their respective counts
print(missing_values)
# Create new columns to store rounded latitude and longitude values
df['latitude_rounded'] = df['latitude'].round(3)
df['longitude_rounded'] = df['longitude'].round(3)

yelp_df['latitude_rounded'] = yelp_df['latitude'].round(3)
yelp_df['longitude_rounded'] = yelp_df['longitude'].round(3)

foursquare_df['latitude_rounded'] = foursquare_df['latitude'].round(3)
foursquare_df['longitude_rounded'] = foursquare_df['longitude'].round(3)

# Merge using the new columns
merged_df = pd.merge(df, foursquare_df, left_on=['latitude_rounded', 'longitude_rounded'], right_on=['latitude_rounded', 'longitude_rounded'], how='left')
merged_df = pd.merge(merged_df, yelp_df, left_on=['latitude_rounded', 'longitude_rounded'], right_on=['latitude_rounded', 'longitude_rounded'], how='left', suffixes=('_foursquare', '_yelp'))

merged_df

columns_to_keep = [
    'latitude_rounded', 'longitude_rounded', 'num_bikes', 
    'name_foursquare', 'category', 'name_yelp', 'rating'
]

merged_df = merged_df[columns_to_keep]

merged_df.head()

# Check for missing values and calculate the count of missing values in each column
missing_values = merged_df.isnull().sum()

# Print the columns with missing values and their respective counts
print(missing_values)

# Remove rows containing missing values
merged_df = merged_df.dropna()

merged_df

# Remove duplicate rows
merged_df = merged_df.drop_duplicates().reset_index(drop=True)

# Check the processed data
merged_df.head()

merged_df.info()

merged_df.to_csv('part3_merged_data.csv', index=False)
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a visualization that you used as part of your EDA process. Explain the initial pattern or relationship you discoved through this visualization. "
   ]
  },
  {
   "cell_type": "code",
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 6))
sns.countplot(x='category', data=merged_df)
plt.title('Number of Bike Stations per Category')
plt.xlabel('Category')
plt.ylabel('Number of Bike Stations')
plt.xticks(rotation=45)
plt.show()

#Plotting average ratings for each category
plt.figure(figsize=(12, 6))
sns.barplot(x='category', y='rating', data=merged_df)
plt.title('Average Rating per Category')
plt.xlabel('Category')
plt.ylabel('Average Rating')
plt.xticks(rotation=45)
plt.show()

#Relationship between number of bicycle stations and ratings
plt.figure(figsize=(10, 6))
sns.scatterplot(x='num_bikes', y='rating', data=merged_df)
plt.title('Relationship Between Number of Bikes and Rating')
plt.xlabel('Number of Bikes')
plt.ylabel('Rating')
plt.show()

plt.figure(figsize=(10, 6))

sns.scatterplot(x='longitude_rounded', y='latitude_rounded', data=merged_df, hue='category', alpha=0.6)

plt.title('Geographical Distribution of Bike Stations')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.legend(title='Category')
plt.grid(True)
plt.show()

   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your results in an SQLite3 database (remember, SQLite stores its databases as files in your local machine - make sure to create your database in your project's data/ directory!)"
   ]
  },
  {
   "cell_type": "code",
import sqlite3

# Create an SQLite database
conn = sqlite3.connect('data/my_database.db')

# Store the DataFrame in the database
merged_df.to_sql('bike_poi_data', conn, if_exists='replace', index=False)

# Verify the data
# Query data from the database
test_df = pd.read_sql_query("SELECT * FROM bike_poi_data", conn)
print(test_df.head())

# Close the database connection
conn.close()

   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data before and after the join to validate your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
